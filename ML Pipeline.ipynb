{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import warnings\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer, TfidfTransformer\n",
    "from sklearn import multioutput\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import nltk\n",
    "nltk.download(['punkt_tab', 'wordnet'])\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(database_filepath):\n",
    "    engine = create_engine('sqlite:///{}'.format(database_filepath))\n",
    "    df = pd.read_sql_table('messages', engine)\n",
    "\n",
    "    X = df['message']\n",
    "    Y = df.iloc[:, 4:]\n",
    "\n",
    "    category_names = Y.columns\n",
    "    return X, Y, category_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y, category_names = load_data(\"../data/DisasterResponse.db\")\n",
    "print(X, Y, category_names,end = \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    url_regex = 'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "    detected_urls = re.findall(url_regex, text)\n",
    "    for url in detected_urls:\n",
    "        text = text.replace(url, \"urlplaceholder\")\n",
    "\n",
    "    tokens = word_tokenize(text)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    clean_tokens = []\n",
    "    for tok in tokens:\n",
    "        clean_tok = lemmatizer.lemmatize(tok).lower().strip()\n",
    "        clean_tokens.append(clean_tok)\n",
    "\n",
    "    return clean_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, Y_test, category_names):\n",
    "    y_pred = model.predict(X_test)\n",
    "    overall_accuracy = (y_pred == Y_test).mean().mean() * 100\n",
    "    y_pred = pd.DataFrame(y_pred, columns=Y_test.columns)\n",
    "\n",
    "    for col in Y_test.columns:\n",
    "        print('Category feature : {}'.format(col.capitalize()))\n",
    "        print('.................................................................\\n')\n",
    "        print(classification_report(Y_test[col], y_pred[col]))\n",
    "        accuracy = (y_pred[col].values == Y_test[col].values).mean().mean() * 100\n",
    "        print('Accuracy: {0:.1f} %\\n'.format(accuracy))\n",
    "\n",
    "    print('Overall Accuracy: {0:.1f} %'.format(overall_accuracy))\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_randomforest():\n",
    "    pipeline = Pipeline([\n",
    "        ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', MultiOutputClassifier(RandomForestClassifier())),\n",
    "    ])\n",
    "\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n",
    "model = build_model_randomforest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, Y_train)\n",
    "evaluate_model(model, X_test, Y_test, category_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_randomizedsearch():\n",
    "    pipeline = Pipeline([\n",
    "        ('features', FeatureUnion([\n",
    "\n",
    "            ('text_pipeline', Pipeline([\n",
    "                ('vect', HashingVectorizer(tokenizer=tokenize, n_features=2**16)),\n",
    "                ('tfidf', TfidfTransformer())\n",
    "            ]))\n",
    "        ])),\n",
    "        ('clf', MultiOutputClassifier(AdaBoostClassifier()))\n",
    "    ])\n",
    "    \n",
    "    parameters = {\n",
    "        'clf__estimator__n_estimators': [50, 100, 200],\n",
    "        'clf__estimator__learning_rate': [0.01, 0.1, 1, 2]\n",
    "    }\n",
    "    \n",
    "    model = RandomizedSearchCV(pipeline, param_distributions=parameters, n_iter=5, cv=3, verbose=2, n_jobs=-1)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "model = joblib.load(\"../models/classifier(randomizedsearch).pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n",
    "evaluate_model(model, X_test, Y_test, category_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    pipeline = Pipeline([\n",
    "        ('features', FeatureUnion([\n",
    "\n",
    "            ('text_pipeline', Pipeline([\n",
    "                ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "                ('tfidf', TfidfTransformer())\n",
    "            ]))\n",
    "        ])),\n",
    "\n",
    "        ('clf', MultiOutputClassifier(AdaBoostClassifier()))\n",
    "    ])\n",
    "\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n",
    "pipeline = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    pipeline.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(model, X_test, Y_test, category_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
